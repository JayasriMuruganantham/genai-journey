{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhi98J1KrOrOEmqqAs39so",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayasriMuruganantham/genai-journey/blob/main/week1_python_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EiQH3PusFQA7",
        "outputId": "88f6688f-4fee-4e77-dfb3-482ee59a55ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Week 1 folder created!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Create week1 folder\n",
        "os.makedirs(\"week1\", exist_ok=True)\n",
        "print(\"Week 1 folder created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple prints\n",
        "print(\"Hello, GenAI World!\")\n",
        "name = \"Jayasri\"\n",
        "print(f\"Welcome, {name}!\")\n",
        "\n",
        "# Basic arithmetic\n",
        "a = 10\n",
        "b = 5\n",
        "print(\"Sum:\", a + b)\n",
        "print(\"Difference:\", a - b)\n"
      ],
      "metadata": {
        "id": "piR31jOf6Fv8",
        "outputId": "4d0c1d16-7b3c-418f-884c-fa1958f29c09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, GenAI World!\n",
            "Welcome, Jayasri!\n",
            "Sum: 15\n",
            "Difference: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    if i % 2 == 0:\n",
        "        print(f\"{i} is even\")\n",
        "    else:\n",
        "        print(f\"{i} is odd\")\n"
      ],
      "metadata": {
        "id": "NiVBI5pS6X30",
        "outputId": "f4c4bea8-1f1c-4883-82ab-8f147d2f80ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 is even\n",
            "1 is odd\n",
            "2 is even\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install transformers torch\n"
      ],
      "metadata": {
        "id": "ohA5DdXH6b5H",
        "outputId": "9c7b0768-61e8-4736-b434-0b2bdcbc3a5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Create text-generation pipeline\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "# Generate text\n",
        "result = generator(\"Hello, I am learning Generative AI:\", max_length=50)\n",
        "\n",
        "# Show output\n",
        "print(\"Generated AI text:\")\n",
        "print(result[0]['generated_text'])\n"
      ],
      "metadata": {
        "id": "HcZGEB6D6idf",
        "outputId": "f647cc77-a332-4ee9-d05e-aac2bd3c1d57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated AI text:\n",
            "Hello, I am learning Generative AI: AI with deep learning and machine learning, and I will try this series as much as possible.\n",
            "\n",
            "The first part of this series will be about how to make the AI that you want. It will cover how to build an AI with deep learning and machine learning. The second part will be about how to create a scalable AI: a distributed machine learning system that is capable of learning about a large number of things.\n",
            "\n",
            "I am starting with Python and the Python programming language, and then I will build a simple Python script to do this.\n",
            "\n",
            "You can use it to develop a simple Python script to build the AI:\n",
            "\n",
            "import random import batch import random import random.randint print(random.randint(100, 5))\n",
            "\n",
            "The script will write a random number generator to generate a random number representing the number of characters in the alphabet and place it in an array.\n",
            "\n",
            "This will give a random number that is 10 characters long and a random number that is 3 characters long.\n",
            "\n",
            "The script will also return a number that will be a random integer and a random number that is 4 characters long.\n",
            "\n",
            "The script will then use the random.randint method to create a random number that will fit the order of the characters in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save output to file\n",
        "with open(\"week1/02_genai_output.txt\", \"w\") as f:\n",
        "    f.write(result[0]['generated_text'])\n",
        "\n",
        "print(\"AI output saved in week1/02_genai_output.txt\")"
      ],
      "metadata": {
        "id": "EdMWw5fN62wq",
        "outputId": "1c3e1df2-4ff0-44fd-b51a-5c9ab0255dae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI output saved in week1/02_genai_output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "readme_content = \"\"\"\n",
        "# Week 1: GenAI Basics\n",
        "\n",
        "## Overview\n",
        "- Python essentials for GenAI\n",
        "- First GenAI text generation using GPT-2\n",
        "- Outputs tracked for verification and portfolio\n",
        "\n",
        "## Files\n",
        "- 01_python_basics.txt → Python exercises\n",
        "- 02_genai_output.txt → GPT-2 generated text\n",
        "- README.md → This file\n",
        "\n",
        "## Instructions\n",
        "1. Open and run Python basics.\n",
        "2. Check AI output in 02_genai_output.txt.\n",
        "3. Experiment by changing the prompt in the notebook.\n",
        "\"\"\"\n",
        "\n",
        "# Save README\n",
        "with open(\"week1/README.md\", \"w\") as f:\n",
        "    f.write(readme_content)\n",
        "\n",
        "print(\"README.md created in week1 folder!\")\n"
      ],
      "metadata": {
        "id": "ntshk1Ft7flq",
        "outputId": "457db445-330f-4ac2-b09c-f34da6f0d648",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md created in week1 folder!\n"
          ]
        }
      ]
    }
  ]
}