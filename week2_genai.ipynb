{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyjcMu9SPDAo4t3BY4RcOo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayasriMuruganantham/genai-journey/blob/main/week2_genai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T34meE5K1oi9",
        "outputId": "6ce8ce34-025f-4cf7-fcaf-220154bb2e9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Week 2 folder created!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Create week2 folder\n",
        "os.makedirs(\"week2\", exist_ok=True)\n",
        "print(\"Week 2 folder created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Hello, GenAI World!')\n",
        "name = 'Jayasri'\n",
        "print(f'Welcome, {name}!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tEmki6e2ZwT",
        "outputId": "9e811705-646f-4d06-c9a3-6482c3ff4e59"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, GenAI World!\n",
            "Welcome, Jayasri!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a, b = 10, 5\n",
        "print('Sum:', a + b)\n",
        "print('Difference:', a - b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-2S2_tl2coo",
        "outputId": "d29daca5-6074-4d27-9a33-c284c1d49379"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum: 15\n",
            "Difference: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    if i % 2 == 0:\n",
        "        print(f'{i} is even')\n",
        "    else:\n",
        "        print(f'{i} is odd')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReqGT15Z2f48",
        "outputId": "f7c1d6d5-bf15-4447-898a-fd8542cf98df"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 is even\n",
            "1 is odd\n",
            "2 is even\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(person):\n",
        "    return f'Hello, {person}!'\n",
        "print(greet('Jayasri'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28Zdit-Z2gKs",
        "outputId": "bf0843df-2058-4222-fac2-14d88aa5a940"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, Jayasri!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "python_code = \"\"\"\\\n",
        "print('Hello, GenAI World!')\n",
        "name = 'Jayasri'\n",
        "print(f'Welcome, {name}!')\n",
        "\n",
        "a, b = 10, 5\n",
        "print('Sum:', a + b)\n",
        "print('Difference:', a - b)\n",
        "\n",
        "for i in range(3):\n",
        "    if i % 2 == 0:\n",
        "        print(f'{i} is even')\n",
        "    else:\n",
        "        print(f'{i} is odd')\n",
        "\n",
        "def greet(person):\n",
        "    return f'Hello, {person}!'\n",
        "print(greet('Jayasri'))\n",
        "\"\"\"\n",
        "\n",
        "# Run the code\n",
        "exec(python_code)\n",
        "\n",
        "# Save to a text file\n",
        "with open(\"week2/02_genai_python.txt\", \"w\") as f:\n",
        "    f.write(python_code)\n",
        "\n",
        "print(\"Python essentials for GenAI saved in week2/02_genai_python.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHQhOYkT3Isx",
        "outputId": "15c373b7-b92a-43da-a56e-d3f3e16aaf66"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, GenAI World!\n",
            "Welcome, Jayasri!\n",
            "Sum: 15\n",
            "Difference: 5\n",
            "0 is even\n",
            "1 is odd\n",
            "2 is even\n",
            "Hello, Jayasri!\n",
            "Python essentials for GenAI saved in week2/02_genai_python.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch --quiet\n",
        "print(\"Transformers and Torch installed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GSuQta23K3S",
        "outputId": "d3a23c8f-c7e8-457e-82b2-540c5154bf9e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers and Torch installed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize GPT-2 text generation\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "# Example prompts\n",
        "prompts = {\n",
        "    \"Story\": \"In a futuristic city, AI robots\",\n",
        "    \"Motivation\": \"Independent life\"\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqrFcprh3aO5",
        "outputId": "5fd49e15-2998-4f1c-8587-351c5e40b179"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate AI outputs\n",
        "output_story = generator(prompts[\"Story\"], max_length=50)\n",
        "output_motivation = generator(prompts[\"Motivation\"], max_length=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnSFcz_y3myV",
        "outputId": "12cca88e-8c8f-41b9-80ac-d9e98cb960a7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show outputs in notebook\n",
        "print(\"=== Story Output ===\")\n",
        "print(output_story[0]['generated_text'])\n",
        "print(\"\\n=== Motivation Output ===\")\n",
        "print(output_motivation[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsYEIce234oV",
        "outputId": "e9df985b-8906-443f-da21-bce836f83b24"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Story Output ===\n",
            "In a futuristic city, AI robots and robots of every color and type can work together to improve the lives of people, communities, and the planet.\n",
            "\n",
            "\"You have a lot of possibilities,\" said Shannan, who is also the president of the National Cyber Security Center, a cyber security research center in Washington. \"As an AI, you can use robotics to solve problems—it can be a form of self-driving car.\"\n",
            "\n",
            "But the way companies and citizens operate on the Internet is increasingly complex, said Shannan, who is also a senior fellow at the Brookings Institution's Center for Cybersecurity and National Security.\n",
            "\n",
            "\"We've got an entire field of expertise in this space,\" he said, \"and a lot of people have the same curiosity about what's possible. And we're all figuring out how to get there.\"\n",
            "\n",
            "=== Motivation Output ===\n",
            "Independent life. The life of a man is about more than how he lives, and the life of a woman is about how he lives.\n",
            "\n",
            "The most important thing is that you don't have to like your man. You don't have to hate your man. You don't have to hate yourself.\n",
            "\n",
            "You don't have to accept being the victim of your man. You don't have to accept how great your man is. You don't have to accept how good your man is. You don't have to believe it. Then you have to do something about it.\n",
            "\n",
            "I would say the best thing you have to do to get rid of your man is to start feeling better about yourself.\n",
            "\n",
            "The thing about having a girl is that you are not expected to be the one who is good at what she does. You are expected to be the one who is good at what she does.\n",
            "\n",
            "If you want to be a great woman, you have to be the one who is the best at what she does.\n",
            "\n",
            "The greatest thing you have to do to get rid of your man is to start feeling better about yourself.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save AI outputs to a text file\n",
        "with open(\"week2/01_genai_outputs.txt\", \"w\") as f:\n",
        "    f.write(\"Story Output:\\n\" + output_story[0]['generated_text'] + \"\\n\\n\")\n",
        "    f.write(\"Motivational Output:\\n\" + output_motivation[0]['generated_text'])\n",
        "\n",
        "print(\"\\nGenAI outputs saved in week2/01_genai_outputs.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suu5J3Vp4DFH",
        "outputId": "ad059724-ed0f-4811-a7bb-df2b35530344"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GenAI outputs saved in week2/01_genai_outputs.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Create README.md for Week 2\n",
        "readme_content = \"\"\"\n",
        "# Week 2: GenAI Basics with Python & Prompt Engineering\n",
        "\n",
        "## Overview\n",
        "- Python essentials for GenAI scripting\n",
        "- Prompt engineering using GPT-2\n",
        "- Save outputs for verification and portfolio\n",
        "\n",
        "## Files\n",
        "- 02_genai_python.txt → Python exercises\n",
        "- 01_genai_outputs.txt → GPT-2 generated text\n",
        "- README.md → Documentation\n",
        "\n",
        "## Key Learning Points\n",
        "- Python control flow and functions\n",
        "- How to write prompts for AI models\n",
        "- Tracking outputs for verification\n",
        "\n",
        "## Instructions\n",
        "1. Open and run `02_genai_python.txt` to see Python exercises.\n",
        "2. Check `01_genai_outputs.txt` to see GPT-2 outputs.\n",
        "3. Modify prompts in the notebook to experiment with different AI text generations.\n",
        "\"\"\"\n",
        "\n",
        "# Save README.md in week2 folder\n",
        "with open(\"week2/README.md\", \"w\") as f:\n",
        "    f.write(readme_content)\n",
        "\n",
        "print(\"README.md created in week2 folder!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMJsZkVC4ZiC",
        "outputId": "403597bc-de84-4f64-b0a0-53fd6ee19fe2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md created in week2 folder!\n"
          ]
        }
      ]
    }
  ]
}